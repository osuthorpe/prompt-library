{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching vector IDs from namespace: bi-internal-ideas\n",
      "Total vector IDs fetched: 2115\n",
      "Fetching embeddings for 2115 vector IDs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Embeddings: 100%|██████████| 22/22 [00:09<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating pairwise similarity with threshold: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Similarity: 100%|██████████| 2115/2115 [04:20<00:00,  8.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates found:\n",
      "ID1: 1057, ID2: 1343, Similarity: 0.9224126332633487\n",
      "ID1: 1057, ID2: 1428, Similarity: 0.9492330376713959\n",
      "ID1: 1342, ID2: 877, Similarity: 0.9044388957220413\n",
      "ID1: 1343, ID2: 1428, Similarity: 0.9411793056984264\n",
      "ID1: 1468, ID2: 1467, Similarity: 0.9999990514307626\n",
      "ID1: 1468, ID2: 1471, Similarity: 0.9475324074467495\n",
      "ID1: 1468, ID2: 1470, Similarity: 0.9475324074467495\n",
      "ID1: 1467, ID2: 1471, Similarity: 0.9475247891294817\n",
      "ID1: 1467, ID2: 1470, Similarity: 0.9475247891294817\n",
      "ID1: 1469, ID2: 1471, Similarity: 0.9076110114831853\n",
      "ID1: 1469, ID2: 1470, Similarity: 0.9076110114831853\n",
      "ID1: 1471, ID2: 1470, Similarity: 1.0\n",
      "ID1: 1710, ID2: 1845, Similarity: 0.9097417833587553\n",
      "ID1: 1732, ID2: 1730, Similarity: 0.9559935107954475\n",
      "ID1: 1948, ID2: 2044, Similarity: 0.9021673468451203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up Pinecone API key and initialize\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "if not pinecone_api_key:\n",
    "    raise ValueError(\"PINECONE_API_KEY is not set in the .env file\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Connect to the index\n",
    "index_name = 'idea-index'\n",
    "namespace = os.getenv(\"PINECONE_NAMESPACE\")\n",
    "\n",
    "details = pc.describe_index(index_name)\n",
    "index = pc.Index(host=details.host)\n",
    "\n",
    "def get_all_vector_ids(index, namespace):\n",
    "    \"\"\"Fetch all vector IDs from the Pinecone index.\"\"\"\n",
    "    vector_ids = []\n",
    "\n",
    "    print(f\"Fetching vector IDs from namespace: {namespace}\")\n",
    "\n",
    "    for ids in index.list(namespace=namespace):\n",
    "        vector_ids.extend(ids)\n",
    "\n",
    "    print(f\"Total vector IDs fetched: {len(vector_ids)}\")\n",
    "\n",
    "    return vector_ids\n",
    "\n",
    "\n",
    "\n",
    "def get_all_embeddings(index, vector_ids, namespace, batch_size=100):\n",
    "    \"\"\"Fetch embeddings and metadata from Pinecone by vector IDs with a progress bar.\"\"\"\n",
    "    print(f\"Fetching embeddings for {len(vector_ids)} vector IDs.\")\n",
    "    embeddings = []\n",
    "\n",
    "    # Wrap the loop with tqdm for a progress bar\n",
    "    for i in tqdm(range(0, len(vector_ids), batch_size), desc=\"Fetching Embeddings\"):\n",
    "        batch_ids = vector_ids[i:i + batch_size]\n",
    "        response = index.fetch(ids=batch_ids, namespace=namespace)\n",
    "        for vector_id, vector_data in response[\"vectors\"].items():\n",
    "            embeddings.append({\n",
    "                \"id\": vector_id,\n",
    "                \"values\": vector_data[\"values\"],\n",
    "                \"metadata\": vector_data[\"metadata\"],\n",
    "            })\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "def pairwise_similarity(embeddings, threshold=0.95):\n",
    "    \"\"\"Perform pairwise similarity between all embeddings.\"\"\"\n",
    "    print(f\"Calculating pairwise similarity with threshold: {threshold}\")\n",
    "    results = []\n",
    "\n",
    "    # Wrap the outer loop with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(embeddings)), desc=\"Pairwise Similarity\"):\n",
    "        for j in range(i + 1, len(embeddings)):  # Avoid duplicate pairs\n",
    "            sim = cosine_similarity(embeddings[i][\"values\"], embeddings[j][\"values\"])\n",
    "            if sim >= threshold:\n",
    "                results.append({\n",
    "                    \"id1\": embeddings[i][\"id\"],\n",
    "                    \"id2\": embeddings[j][\"id\"],\n",
    "                    \"similarity\": sim,\n",
    "                    \"metadata1\": embeddings[i][\"metadata\"],\n",
    "                    \"metadata2\": embeddings[j][\"metadata\"]\n",
    "                })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Step 1: Fetch all vector IDs\n",
    "vector_ids = get_all_vector_ids(index, namespace)\n",
    "\n",
    "# Step 2: Fetch all embeddings\n",
    "embeddings = get_all_embeddings(index, vector_ids, namespace)\n",
    "\n",
    "# Step 3: Calculate pairwise similarity\n",
    "if embeddings:\n",
    "    threshold = 0.90  # Adjust threshold as needed\n",
    "    similar_items = pairwise_similarity(embeddings, threshold=threshold)\n",
    "    if similar_items:\n",
    "        print(\"Duplicates found:\")\n",
    "        for item in similar_items:\n",
    "            print(f\"ID1: {item['id1']}, ID2: {item['id2']}, Similarity: {item['similarity']}\")\n",
    "    else:\n",
    "        print(\"No duplicates found.\")\n",
    "else:\n",
    "    print(\"No embeddings found in the index.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
