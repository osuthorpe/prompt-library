{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "if not pinecone_api_key:\n",
    "    raise ValueError(\"PINECONE_API_KEY is not set in the .env file\")\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Step 1: Load the preprocessed data\n",
    "file_path = os.path.expanduser(\"~/Desktop/Preprocessing/Ideas_Cleaned.csv\")  # Adjust path as needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure 'LemmatizedText' is cleaned and valid\n",
    "data = data.dropna(subset=['LemmatizedText'])\n",
    "data = data[data['LemmatizedText'].str.strip() != \"\"]\n",
    "data['LemmatizedText'] = data['LemmatizedText'].astype(str)\n",
    "\n",
    "# Limit to the first 100 rows\n",
    "limited_data = data.head(1000).copy()\n",
    "\n",
    "# Initialize an empty list to store embeddings\n",
    "embeddings_list = []\n",
    "\n",
    "# Process each row one by one\n",
    "for index, row in limited_data.iterrows():\n",
    "    # Call the API for each LemmatizedText entry\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        input=row['LemmatizedText']  # Single string input\n",
    "    )\n",
    "    # Extract the embedding and validate\n",
    "    embedding = response.data[0].embedding\n",
    "    if not isinstance(embedding, list) or not all(isinstance(v, float) for v in embedding):\n",
    "        raise ValueError(f\"Invalid embedding at index {index}: {embedding}\")\n",
    "    \n",
    "    # Append the valid embedding to the list\n",
    "    embeddings_list.append(embedding)\n",
    "\n",
    "    # Print progress\n",
    "    if index % 10 == 0:\n",
    "        print(f\"Processed {index} entries...\")\n",
    "\n",
    "# Add embeddings back to the DataFrame\n",
    "limited_data['Embeddings'] = embeddings_list\n",
    "\n",
    "# Step 2: Prepare data for Pinecone upsertion\n",
    "upsert_data = [\n",
    "    {\n",
    "        \"id\": str(index),  # Unique identifier for each entry\n",
    "        \"values\": embedding,  # Embedding vector\n",
    "        \"metadata\": {         # Include metadata for search and filtering\n",
    "            \"title\": row['Title'],\n",
    "            \"description\": row['Description'],\n",
    "            \"category\": row.get('Category', ''),\n",
    "            \"status\": row.get('Status', ''),\n",
    "            \"submitter\": row.get('Submitter', ''),\n",
    "            \"date_submitted\": row.get('Submitted', ''),\n",
    "        }\n",
    "    }\n",
    "    for index, (embedding, row) in enumerate(zip(embeddings_list, data.to_dict(orient='records')))\n",
    "]\n",
    "\n",
    "# Validate the upsert data\n",
    "for item in upsert_data:\n",
    "    if not isinstance(item[\"values\"], list) or not all(isinstance(v, float) for v in item[\"values\"]):\n",
    "        raise ValueError(f\"Invalid values in upsert data: {item['values']}\")\n",
    "\n",
    "# Step 3: Create or connect to a Pinecone index\n",
    "index_name = \"idea-index\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=3072,  # Set to the embedding dimension (3072 for this model)\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws', \n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Wait for the index to be ready\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Step 4: Upsert data to Pinecone\n",
    "batch_size = 10  # Process data in batches\n",
    "for i in range(0, len(upsert_data), batch_size):\n",
    "    batch = upsert_data[i:i + batch_size]\n",
    "    index.upsert(\n",
    "        vectors=batch,\n",
    "        namespace=\"bi-internal-ideas\"\n",
    "    )\n",
    "\n",
    "print(\"Data successfully upserted to Pinecone!\")\n",
    "\n",
    "# Step 5: Query the Pinecone index\n",
    "def query_pinecone(query_text, index, top_k=5):\n",
    "    \"\"\"Query Pinecone index with a text input.\"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        input=query_text\n",
    "    )\n",
    "    query_embedding = response.data[0].embedding\n",
    "    result = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        namespace=\"bi-internal-ideas\"\n",
    "    )\n",
    "    return result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
