{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "if not pinecone_api_key:\n",
    "    raise ValueError(\"PINECONE_API_KEY is not set in the .env file\")\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to clean metadata comprehensively\n",
    "def clean_metadata(row):\n",
    "    \"\"\"Clean metadata fields to ensure no NaN or invalid values.\"\"\"\n",
    "    metadata = {\n",
    "        \"title\": row.get(\"Title\", \"\"),\n",
    "        \"description\": row.get(\"Description\", \"\"),\n",
    "        \"difference\": row.get(\"How is the proposed idea different from previous attempts?\", \"\"),\n",
    "        \"benefits\": row.get(\"What is in it for the customer, the department, the company?\", \"\"),\n",
    "        \"category\": row.get(\"Category\", \"\"),\n",
    "        \"status\": row.get(\"Status\", \"\"),\n",
    "        \"submitter\": row.get(\"Submitter\", \"\"),\n",
    "        \"date_submitted\": row.get(\"Submitted\", \"\"),\n",
    "        \"comments\": row.get(\"Comments\", \"\")\n",
    "    }\n",
    "    \n",
    "    # Replace any NaN or non-string values\n",
    "    for key, value in metadata.items():\n",
    "        if pd.isna(value) or not isinstance(value, str):\n",
    "            metadata[key] = \"\"  # Replace with empty string\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "# Step 1: Load and preprocess the data\n",
    "file_path = os.path.expanduser(\"~/Desktop/Preprocessing/Ideas_Cleaned.csv\")  # Adjust path as needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure 'LemmatizedText' is cleaned and valid\n",
    "data = data.dropna(subset=[\"LemmatizedText\"])\n",
    "data = data[data[\"LemmatizedText\"].str.strip() != \"\"]\n",
    "data[\"LemmatizedText\"] = data[\"LemmatizedText\"].astype(str)\n",
    "\n",
    "# Limit to the first N rows for demonstration\n",
    "limited_data = data.head(3000).copy()\n",
    "\n",
    "# Step 2: Generate embeddings sequentially\n",
    "embeddings_list = []\n",
    "for row_text in tqdm(limited_data[\"LemmatizedText\"], desc=\"Generating embeddings\"):\n",
    "    response = client.embeddings.create(model=\"text-embedding-3-large\", input=row_text)\n",
    "    embedding = response.data[0].embedding\n",
    "    if not isinstance(embedding, list) or not all(isinstance(v, float) for v in embedding):\n",
    "        raise ValueError(f\"Invalid embedding: {embedding}\")\n",
    "    embeddings_list.append(embedding)\n",
    "\n",
    "# Add embeddings back to the DataFrame\n",
    "limited_data[\"Embeddings\"] = embeddings_list\n",
    "\n",
    "# Step 3: Prepare data for Pinecone upsertion\n",
    "upsert_data = [\n",
    "    {\n",
    "        \"id\": str(index),  # Unique identifier for each entry\n",
    "        \"values\": embedding,  # Embedding vector\n",
    "        \"metadata\": clean_metadata(row)\n",
    "    }\n",
    "    for index, (embedding, row) in enumerate(zip(embeddings_list, limited_data.to_dict(orient=\"records\")))\n",
    "]\n",
    "\n",
    "# Verify upsert data\n",
    "print(\"Sample Upsert Data:\")\n",
    "print(upsert_data[:3])  # Print the first 3 records to verify structure\n",
    "\n",
    "# Step 4: Create or connect to a Pinecone index\n",
    "index_name = \"idea-index\"\n",
    "namespace = \"bi-internal-ideas\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=3072,  # Set to the embedding dimension (3072 for this model)\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "# Wait for the index to be ready\n",
    "while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "    time.sleep(1)\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Step 5: Upsert data to Pinecone\n",
    "batch_size = 10  # Process data in batches\n",
    "for i in range(0, len(upsert_data), batch_size):\n",
    "    batch = upsert_data[i:i + batch_size]\n",
    "    response = index.upsert(vectors=batch, namespace=namespace)\n",
    "    print(f\"Upsert response for batch {i // batch_size + 1}: {response}\")\n",
    "\n",
    "# Check namespace stats after upsertion\n",
    "stats = index.describe_index_stats()\n",
    "print(f\"Namespace Stats after upsertion: {stats['namespaces']}\")\n",
    "\n",
    "print(\"Data successfully upserted to Pinecone!\")\n",
    "\n",
    "# Step 6: Query the Pinecone index\n",
    "def query_pinecone(query_text, index, namespace, top_k=5):\n",
    "    \"\"\"Query Pinecone index with a text input.\"\"\"\n",
    "    print(\"Validating Pinecone index...\")\n",
    "\n",
    "    # Validate the index\n",
    "    try:\n",
    "        index_stats = index.describe_index_stats()\n",
    "        print(\"Index is valid. Stats:\")\n",
    "        print(index_stats)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to validate the index. Error:\")\n",
    "        raise e\n",
    "\n",
    "    print(\"Generating query embedding...\")\n",
    "    # Generate embedding for the query\n",
    "    response = client.embeddings.create(model=\"text-embedding-3-large\", input=query_text)\n",
    "    query_embedding = response.data[0].embedding\n",
    "\n",
    "    if not isinstance(query_embedding, list) or not all(isinstance(v, float) for v in query_embedding):\n",
    "        raise ValueError(\"Query embedding is invalid.\")\n",
    "\n",
    "    print(\"Querying Pinecone index...\")\n",
    "    # Query Pinecone\n",
    "    result = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        namespace=namespace\n",
    "    )\n",
    "    print(f\"Query successful. Retrieved {len(result['matches'])} results.\")\n",
    "    return result\n",
    "\n",
    "# Function to wait for Pinecone index readiness\n",
    "def wait_for_pinecone_index(index, namespace, max_wait=30, interval=2):\n",
    "    \"\"\"Wait for Pinecone index to be ready for querying.\"\"\"\n",
    "    waited = 0\n",
    "    while waited < max_wait:\n",
    "        stats = index.describe_index_stats()\n",
    "        vector_count = stats[\"namespaces\"].get(namespace, {}).get(\"vector_count\", 0)\n",
    "        if vector_count > 0:\n",
    "            print(f\"Pinecone index is ready with {vector_count} vectors in namespace '{namespace}'.\")\n",
    "            return\n",
    "        print(f\"Waiting for Pinecone index... (elapsed time: {waited}s)\")\n",
    "        time.sleep(interval)\n",
    "        waited += interval\n",
    "    raise TimeoutError(f\"Pinecone index not ready after {max_wait} seconds.\")\n",
    "\n",
    "# Example query\n",
    "query_text = \"How can we improve collaboration in teams?\"\n",
    "\n",
    "# Wait for the Pinecone index to be ready\n",
    "wait_for_pinecone_index(index, namespace, max_wait=60, interval=5)\n",
    "\n",
    "# Perform the query\n",
    "result = query_pinecone(query_text, index, namespace, top_k=5)\n",
    "\n",
    "# Print results\n",
    "print(\"Query Results:\")\n",
    "for match in result.get(\"matches\", []):\n",
    "    print(f\"ID: {match['id']}, Score: {match['score']}, Metadata: {match['metadata']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
