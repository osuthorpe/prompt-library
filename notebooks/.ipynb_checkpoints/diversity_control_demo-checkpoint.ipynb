{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b026523-6499-440a-8666-5fa699b508ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi there! Can you tell me about renewable energy?\n",
      "Agent: ChatCompletionMessage(content='Hello! Renewable energy refers to energy that is generated from natural resources that are replenished on a human timescale. These resources include sunlight, wind, rain, tides, waves, and geothermal heat. Unlike fossil fuels, which are finite and emit greenhouse gases when burned, renewable energy sources are generally more sustainable and environmentally friendly. Here are some of the main types of renewable energy:\\n\\n1. **Solar Energy**: This is harnessed from the sun using technologies like solar panels and solar thermal collectors. Solar energy can be used for electricity generation, heating, and even cooling.\\n\\n2. **Wind Energy**: Wind turbines convert the kinetic energy from wind into mechanical power, which can then be converted into electricity. Wind farms can be located onshore or', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ChatCompletionMessage' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 223\u001b[0m\n\u001b[1;32m    221\u001b[0m     response \u001b[38;5;241m=\u001b[39m generate_response(user_input, diversity_level)\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAgent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 223\u001b[0m     \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_response_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     all_responses\u001b[38;5;241m.\u001b[39mappend(response)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngagement Metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 179\u001b[0m, in \u001b[0;36mEngagementMetrics.log_response_length\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_response_length\u001b[39m(\u001b[38;5;28mself\u001b[39m, response):\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m()))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.11/envs/venv/lib/python3.9/site-packages/pydantic/main.py:892\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 892\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ChatCompletionMessage' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# ============================== #\n",
    "# Diversity Control Framework Implementation\n",
    "# ============================== #\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Setup and Imports\n",
    "# ------------------------------\n",
    "\n",
    "# Install required libraries (uncomment if not already installed)\n",
    "# !pip install torch openai sentence-transformers scikit-learn pyyaml\n",
    "\n",
    "import os\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import openai\n",
    "import time\n",
    "import json\n",
    "import yaml  # Required for loading secrets\n",
    "\n",
    "def load_secrets(file_path=\"../supporting_files/secrets.yaml\"):\n",
    "    \"\"\"\n",
    "    Load API keys from the secrets file.\n",
    "    Raises an error if the file is missing or improperly formatted.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Secrets file not found at: {file_path}\")\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return yaml.safe_load(file)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load secrets file: {e}\")\n",
    "\n",
    "# Load secrets\n",
    "secrets = load_secrets()\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Configuration\n",
    "# ------------------------------\n",
    "\n",
    "# Pull the OpenAI API key from the secrets file\n",
    "openai.api_key = secrets['openai_api_key']\n",
    "\n",
    "# Initialize the sentence transformer model for SVS\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define target entropy for diversity\n",
    "TARGET_ENTROPY = 1.5  # Example value\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Diversity Metrics Implementation\n",
    "# ------------------------------\n",
    "\n",
    "def calculate_entropy(responses):\n",
    "    \"\"\"\n",
    "    Calculates Entropy Diversity (ED) of the given responses.\n",
    "    \n",
    "    Parameters:\n",
    "    - responses (list of str): List of response texts.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Entropy value.\n",
    "    \"\"\"\n",
    "    count = Counter(responses)\n",
    "    total = len(responses)\n",
    "    entropy = -sum((freq/total) * math.log(freq/total) for freq in count.values())\n",
    "    return entropy\n",
    "\n",
    "def calculate_svs(responses):\n",
    "    \"\"\"\n",
    "    Calculates Semantic Variation Score (SVS) of the given responses.\n",
    "    \n",
    "    Parameters:\n",
    "    - responses (list of str): List of response texts.\n",
    "    \n",
    "    Returns:\n",
    "    - float: SVS value.\n",
    "    \"\"\"\n",
    "    if len(responses) < 2:\n",
    "        return 0\n",
    "    embeddings = model.encode(responses)\n",
    "    n = len(embeddings)\n",
    "    similarity = cosine_similarity(embeddings)\n",
    "    total_distance = 0\n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            distance = 1 - similarity[i][j]\n",
    "            total_distance += distance\n",
    "            count += 1\n",
    "    return total_distance / count if count != 0 else 0\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Control Algorithms Development\n",
    "# ------------------------------\n",
    "\n",
    "def dynamic_diversity_control(current_entropy, target_entropy, adjustment_factor=0.1):\n",
    "    \"\"\"\n",
    "    Adjusts diversity level based on current entropy compared to target entropy.\n",
    "    \n",
    "    Parameters:\n",
    "    - current_entropy (float): Current entropy value.\n",
    "    - target_entropy (float): Desired target entropy.\n",
    "    - adjustment_factor (float): Step size for adjustment.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Updated diversity level.\n",
    "    \"\"\"\n",
    "    if current_entropy < target_entropy:\n",
    "        new_diversity = min(current_entropy + adjustment_factor, target_entropy)\n",
    "    else:\n",
    "        new_diversity = max(current_entropy - adjustment_factor, target_entropy)\n",
    "    return new_diversity\n",
    "\n",
    "def context_aware_diversity_regulation(conversation_context, user_profile=None):\n",
    "    \"\"\"\n",
    "    Determines diversity level based on conversation context and user profile.\n",
    "    \n",
    "    Parameters:\n",
    "    - conversation_context (str): Current user input.\n",
    "    - user_profile (dict, optional): User profile data.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Diversity level between 0 and 1.\n",
    "    \"\"\"\n",
    "    topic_length = len(conversation_context.split())\n",
    "    if topic_length < 10:\n",
    "        return 0.2  # Low diversity for short topics\n",
    "    elif topic_length < 50:\n",
    "        return 0.5  # Medium diversity\n",
    "    return 0.7  # High diversity for long topics\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Integration with LLM (GPT-4)\n",
    "# ------------------------------\n",
    "\n",
    "def generate_response(user_content, diversity_level):\n",
    "    \"\"\"\n",
    "    Generates a response from the LLM with controlled diversity.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_content (str): The user input content.\n",
    "    - diversity_level (float): A value between 0 and 1 indicating desired diversity.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The generated response from the LLM.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # Replace with \"text-davinci-003\" if GPT-4 is unavailable\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_content}\n",
    "            ],\n",
    "            max_tokens=150,\n",
    "            temperature=diversity_level,  # Temperature controls diversity\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0.0,\n",
    "            presence_penalty=0.0\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# ------------------------------\n",
    "# 6. User Engagement Metrics Tracking\n",
    "# ------------------------------\n",
    "\n",
    "class EngagementMetrics:\n",
    "    def __init__(self):\n",
    "        self.response_lengths = []\n",
    "        self.user_response_times = []\n",
    "        self.interaction_durations = []\n",
    "        self.repeat_interaction_count = 0\n",
    "        self.total_interactions = 0\n",
    "\n",
    "    def log_response_length(self, response):\n",
    "        self.response_lengths.append(len(response.split()))\n",
    "\n",
    "    def log_user_response_time(self, response_time):\n",
    "        self.user_response_times.append(response_time)\n",
    "\n",
    "    def log_interaction_duration(self, duration):\n",
    "        self.interaction_durations.append(duration)\n",
    "\n",
    "    def log_repeat_interaction(self):\n",
    "        self.repeat_interaction_count += 1\n",
    "\n",
    "    def log_interaction(self):\n",
    "        self.total_interactions += 1\n",
    "\n",
    "    def get_metrics(self):\n",
    "        return {\n",
    "            \"Average Response Length\": sum(self.response_lengths) / len(self.response_lengths) if self.response_lengths else 0,\n",
    "            \"Average User Response Time (s)\": sum(self.user_response_times) / len(self.user_response_times) if self.user_response_times else 0,\n",
    "            \"Average Interaction Duration (s)\": sum(self.interaction_durations) / len(self.interaction_durations) if self.interaction_durations else 0,\n",
    "            \"Repeat Interaction Rate\": self.repeat_interaction_count / self.total_interactions if self.total_interactions else 0\n",
    "        }\n",
    "\n",
    "# ------------------------------\n",
    "# 7. Sample Dataset Description\n",
    "# ------------------------------\n",
    "\n",
    "sample_conversations = [\n",
    "    {\"user\": \"Hi there! Can you tell me about renewable energy?\", \"context\": \"\"},\n",
    "    {\"user\": \"I'm feeling down today. Any advice?\", \"context\": \"\"},\n",
    "    {\"user\": \"Explain the theory of relativity.\", \"context\": \"\"}\n",
    "]\n",
    "\n",
    "# ------------------------------\n",
    "# 8. Running the Diversity Control Framework\n",
    "# ------------------------------\n",
    "\n",
    "metrics = EngagementMetrics()\n",
    "all_responses = []\n",
    "\n",
    "for convo in sample_conversations:\n",
    "    user_input = convo[\"user\"]\n",
    "    diversity_level = context_aware_diversity_regulation(user_input)\n",
    "    response = generate_response(user_input, diversity_level)\n",
    "    print(f\"User: {user_input}\\nAgent: {response}\\n\")\n",
    "    metrics.log_response_length(response)\n",
    "    all_responses.append(response)\n",
    "\n",
    "print(\"Engagement Metrics:\")\n",
    "print(metrics.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09afe72f-5100-4316-a223-e47a78503604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
