{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a RAG search engine powered by Openai and Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Query: Searching for concepts, designs, or implementations related to customizable dashboards, real-time data visualization, interactive user interfaces, personalized analytics displays, dynamic information panels, and adaptable reporting platforms.\n",
      "\n",
      "There are several ideas related to creating configurable dashboards that cater to individual or organizational needs. One prominent concept is the development of a tool that enables users to build their own analytics dashboards without needing technical assistance. This tool would allow users to use a drag-and-drop interface similar to Excel Pivot Tables or Salesforce Report Builder to customize dashboards by selecting specific data fields and visual formats, producing graphical charts tailored to their needs. Access to such a feature could potentially be monetized by offering different tiers, such as 'Analytics Simple' versus 'Analytics Pro'.\n",
      "\n",
      "Another suggestion is to enhance dashboards by adding widgets that provide quick access to key business intelligence metrics, like the most popular idea categories among employees, or engagement levels across different areas. These widgets would enhance admin dashboards by presenting relevant data at-a-glance, without the need for deep dives into more complex reporting features.\n",
      "\n",
      "Additionally, the integration of a customizable temporal view to track activity trends across various levels (initiative, community, and enterprise) could offer a dynamic perspective on engagement metrics over time.\n",
      "\n",
      "These ideas underline a common theme of making dashboards more user-friendly and tailored to specific analytical requirements, providing both flexibility in configuration and depth in insight.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up Pinecone API key and initialize\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "if not pinecone_api_key:\n",
    "    raise ValueError(\"PINECONE_API_KEY is not set in the .env file\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Connect to the index\n",
    "index_name = 'idea-index'\n",
    "namespace = os.getenv(\"PINECONE_NAMESPACE\")\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Define functions\n",
    "def get_embeddings(text, model=\"text-embedding-3-large\"):\n",
    "    \"\"\"Generate embeddings using OpenAI.\"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def get_chat_completion(messages, model, response_format=None):\n",
    "    \"\"\"Generate chat completion using OpenAI.\"\"\"\n",
    "    completion_params = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages\n",
    "    }\n",
    "    \n",
    "    if response_format:\n",
    "        completion_params[\"response_format\"] = response_format\n",
    "\n",
    "    completion = client.chat.completions.create(**completion_params)\n",
    "\n",
    "    result = completion.choices[0].message.content\n",
    "\n",
    "    return result\n",
    "\n",
    "def build_cosine_query(query_text):\n",
    "    \"\"\"Build a cosine similarity query.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"developer\", \"content\": \"You are a helpful innovation assistant. Format my question in a way that would get the best results from a vector search of ideas in my database. The ideas have been embedded with their Title, Description, and Comments combined and lemmatized before uploading. I am going to take the output of this and give it to Pinecone to perform a cosine similarity search.\"},\n",
    "        {\"role\": \"user\", \"content\": \"I want to find ideas related to renewable energy sources.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Looking for innovative ideas, projects, or discussions related to renewable energy sources (e.g. solar, wind, hydroelectric, geothermal, biomass), clean energy technologies, sustainable power generation, reduced carbon footprint, zero-emission strategies, and other eco-friendly solutions.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some innovative ideas for increasing revenue?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Seeking creative and novel concepts, strategies, or initiatives to boost income, generate profits, enhance financial performance, drive sales growth, improve monetization, optimize revenue streams, or maximize earnings.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How can I improve customer satisfaction in my business?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Exploring methods, techniques, approaches, or practices to enhance customer experience, increase client happiness, elevate service quality, improve customer relations, foster client loyalty, or deliver exceptional customer service.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some ideas for reducing waste in manufacturing processes?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Investigating innovative solutions, strategies, technologies, or methodologies to minimize waste production, reduce resource consumption, optimize material efficiency, enhance sustainability, or implement eco-friendly practices in manufacturing operations.\"},\n",
    "        {\"role\": \"user\", \"content\": query_text}\n",
    "    ]\n",
    "\n",
    "    response_format = {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"query_schema\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"result\": {\n",
    "                        \"description\": \"The reformatted query string to use for cosine similarity search on the vector database.\",\n",
    "                        \"type\": \"string\"\n",
    "                    }\n",
    "                },\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = get_chat_completion(messages, model=\"gpt-4o\", response_format=response_format)\n",
    "\n",
    "    # Parse the JSON response\n",
    "    response_json = json.loads(response)\n",
    "\n",
    "    query = response_json[\"result\"]  # Safely access \"result\" key from JSON response\n",
    "\n",
    "    return query\n",
    "\n",
    "def query_pinecone(query_text, index, top_k=10):\n",
    "    \"\"\"Query Pinecone index with a text input.\"\"\"\n",
    "    query_embedding = get_embeddings(query_text)\n",
    "    response = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        namespace=namespace\n",
    "    )\n",
    "\n",
    "    # Convert response to a dictionary\n",
    "    response_dict = response.to_dict()  # Use Pinecone's `to_dict()` method if available\n",
    "\n",
    "    return response_dict\n",
    "\n",
    "def generate_response(query_text, response_dict):\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"developer\", \n",
    "         \"content\": (\n",
    "            \"You are a helpful innovation assistant. Use the following ideas to answer the user's question.\"\n",
    "            f\"Use the following ideas to answer the user's question:\\n\"\n",
    "            f\"{json.dumps(response_dict, indent=2)}\\n\"  # Serialize response to JSON format\n",
    "            f\"### Instructions:\\n\"\n",
    "            f\"- Focus your response on the user's query.\\n\"\n",
    "            f\"- Use the provided ideas to give specific, actionable answers.\\n\"\n",
    "            f\"- If no ideas seem directly relevant, provide general advice or suggest next steps for the user to refine their question.\\n\\n\"\n",
    "            f\"- Summarize the key points from the ideas that are most relevant to the user's query as one narrative.\\n\"\n",
    "            f\"- Provide a clear and concise response that addresses the user's query based on the ideas provided. Do not just list the ideas.\"\n",
    "        )},\n",
    "        {\"role\": \"user\", \"content\": query_text}\n",
    "    ]\n",
    "\n",
    "    respone_format = {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"response_schema\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"response\": {\n",
    "                        \"description\": \"The response to the user's query based on the retrieved ideas.\",\n",
    "                        \"type\": \"string\"\n",
    "                    }\n",
    "                },\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = get_chat_completion(messages, model=\"gpt-4o\", response_format=respone_format)\n",
    "\n",
    "    # Parse the JSON response\n",
    "    response_json = json.loads(response)\n",
    "\n",
    "    query = response_json[\"response\"]  # Safely access \"result\" key from JSON response\n",
    "    \n",
    "    return query\n",
    "\n",
    "# Interactive Cells\n",
    "# Query Example\n",
    "query_text = input(\"\\nEnter a query to search the ideaspace: \")\n",
    "\n",
    "cosine_query = build_cosine_query(query_text)\n",
    "print(f\"\\nCosine Query: {cosine_query}\\n\")\n",
    "\n",
    "pinecone_results = query_pinecone(cosine_query, index)\n",
    "\n",
    "response = generate_response(query_text, pinecone_results)\n",
    "\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
