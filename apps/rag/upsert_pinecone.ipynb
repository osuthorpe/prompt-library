{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 entries...\n",
      "     Code              Category         Submitted             Submitter  \\\n",
      "0  D27603           Enhancement  12/20/2024 18:54               J Leone   \n",
      "1  D27602           Enhancement  12/19/2024 10:25               J Leone   \n",
      "2  D27600           Enhancement  12/18/2024 11:09  Brian Wermerskirchen   \n",
      "3  D27599           Enhancement  12/17/2024 15:53       Emerson Lambert   \n",
      "4  D27595  Reporting/Dashboards  12/13/2024 19:59         France Dreyer   \n",
      "\n",
      "                  Submitter email Team Name Submission Team  \\\n",
      "0           jleone@brightidea.com       NaN             NaN   \n",
      "1           jleone@brightidea.com       NaN             NaN   \n",
      "2  bwermerskirchen@brightidea.com       NaN             NaN   \n",
      "3         elambert@brightidea.com       NaN             NaN   \n",
      "4          fdreyer@brightidea.com       NaN             NaN   \n",
      "\n",
      "  Submission Team email                                              Title  \\\n",
      "0                   NaN                                AI-First Whiteboard   \n",
      "1                   NaN        Use Rules for Ad-Hoc Action Item Assignment   \n",
      "2                   NaN  Add API endpoint for Login History report data...   \n",
      "3                   NaN  Customizable analyst role with permission adju...   \n",
      "4                   NaN      Include All Users in the User Activity Report   \n",
      "\n",
      "                                         Description  ...  \\\n",
      "0  I was thinking AI-first whiteboard is basicall...  ...   \n",
      "1  Create an \"action\" for rules which is to \"Upda...  ...   \n",
      "2  When clients use the API to pull Login History...  ...   \n",
      "3  The current role options in Brightidea are too...  ...   \n",
      "4  Enhance the User Activity Report to include al...  ...   \n",
      "\n",
      "                      External ID Joined Event            Join Date  \\\n",
      "0           jleone@brightidea.com           No                  NaN   \n",
      "1           jleone@brightidea.com           No                  NaN   \n",
      "2  bwermerskirchen@brightidea.com           No                  NaN   \n",
      "3         elambert@brightidea.com           No                  NaN   \n",
      "4          fdreyer@brightidea.com          Yes  2024-09-30 20:38:20   \n",
      "\n",
      "                Join Method  Attachments URLs  Jira Links  \\\n",
      "0                       NaN               NaN         NaN   \n",
      "1                       NaN               NaN         NaN   \n",
      "2                       NaN               NaN         NaN   \n",
      "3                       NaN               NaN         NaN   \n",
      "4  Added to submission team               NaN         NaN   \n",
      "\n",
      "                                        CombinedText  \\\n",
      "0  aifirst whiteboard i was thinking aifirst whit...   \n",
      "1  use rules for adhoc action item assignment cre...   \n",
      "2  add api endpoint for login history report data...   \n",
      "3  customizable analyst role with permission adju...   \n",
      "4  include all users in the user activity report ...   \n",
      "\n",
      "                                         CleanedText  \\\n",
      "0  aifirst whiteboard thinking aifirst whiteboard...   \n",
      "1  use rules adhoc action item assignment create ...   \n",
      "2  add api endpoint login history report data ret...   \n",
      "3  customizable analyst role permission adjustmen...   \n",
      "4  include users user activity report enhance use...   \n",
      "\n",
      "                                      LemmatizedText  \\\n",
      "0  aifirst whiteboard thinking aifirst whiteboard...   \n",
      "1  use rule adhoc action item assignment create a...   \n",
      "2  add api endpoint login history report data ret...   \n",
      "3  customizable analyst role permission adjustmen...   \n",
      "4  include user user activity report enhance user...   \n",
      "\n",
      "                                          Embeddings  \n",
      "0  [-0.036632307, -0.024716863, -0.023830889, -0....  \n",
      "1  [-0.034185465, -0.0030428427, -0.0023266443, 0...  \n",
      "2  [-0.0374909, 0.008090951, 0.0002615609, -0.002...  \n",
      "3  [-0.05693348, -0.024966339, -0.0024115213, -0....  \n",
      "4  [-0.004446253, 0.0033748434, -0.016876176, -0....  \n",
      "\n",
      "[5 rows x 82 columns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PineconeGRPC' object has no attribute 'has_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Step 4: Create or connect to a Pinecone index\u001b[39;00m\n\u001b[1;32m     78\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midea-index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_index\u001b[49m(index_name):\n\u001b[1;32m     81\u001b[0m     pc\u001b[38;5;241m.\u001b[39mcreate_index(\n\u001b[1;32m     82\u001b[0m         name\u001b[38;5;241m=\u001b[39mindex_name,\n\u001b[1;32m     83\u001b[0m         dimension\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3072\u001b[39m,  \u001b[38;5;66;03m# Set to the embedding dimension (3072 for this model)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m         )\n\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Wait for the index to be ready\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PineconeGRPC' object has no attribute 'has_index'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "if not pinecone_api_key:\n",
    "    raise ValueError(\"PINECONE_API_KEY is not set in the .env file\")\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Step 1: Load the preprocessed data\n",
    "file_path = os.path.expanduser(\"~/Desktop/Preprocessing/Ideas_Cleaned.csv\")  # Adjust path as needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure 'LemmatizedText' is cleaned and valid\n",
    "data = data.dropna(subset=['LemmatizedText'])\n",
    "data = data[data['LemmatizedText'].str.strip() != \"\"]\n",
    "data['LemmatizedText'] = data['LemmatizedText'].astype(str)\n",
    "\n",
    "# Limit to the first 100 rows\n",
    "limited_data = data.head(5).copy()\n",
    "\n",
    "# Initialize an empty list to store embeddings\n",
    "embeddings_list = []\n",
    "\n",
    "# Process each row one by one\n",
    "for index, row in limited_data.iterrows():\n",
    "    # Call the API for each LemmatizedText entry\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        input=row['LemmatizedText'],  # Single string input\n",
    "        encoding_format=\"float\"\n",
    "    )\n",
    "    # Extract the embedding and append to the list\n",
    "    embeddings_list.append(response.data[0].embedding)\n",
    "\n",
    "    # Print progress\n",
    "    if index % 10 == 0:\n",
    "        print(f\"Processed {index} entries...\")\n",
    "\n",
    "# Add embeddings back to the DataFrame\n",
    "#data['Embeddings'] = embeddings_list\n",
    "limited_data['Embeddings'] = embeddings_list\n",
    "\n",
    "# Verify results\n",
    "print(limited_data.head())\n",
    "\n",
    "\n",
    "# Step 3: Prepare data for Pinecone upsertion\n",
    "upsert_data = [\n",
    "    {\n",
    "        \"id\": str(index),  # Unique identifier for each entry\n",
    "        \"values\": embedding,  # Embedding vector\n",
    "        \"metadata\": {         # Include metadata for search and filtering\n",
    "            \"title\": row['Title'],\n",
    "            \"description\": row['Description'],\n",
    "            \"category\": row.get('Category', ''),\n",
    "            \"status\": row.get('Status', ''),\n",
    "            \"submitter\": row.get('Submitter', ''),\n",
    "            \"date_submitted\": row.get('Submitted', ''),\n",
    "        }\n",
    "    }\n",
    "    for index, (embedding, row) in enumerate(zip(limited_data, data.to_dict(orient='records')))\n",
    "]\n",
    "\n",
    "# Step 4: Create or connect to a Pinecone index\n",
    "index_name = \"idea-index\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=3072,  # Set to the embedding dimension (3072 for this model)\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws', \n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Wait for the index to be ready\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Step 5: Upsert data to Pinecone\n",
    "batch_size = 10  # Process data in batches\n",
    "for i in range(0, len(upsert_data), batch_size):\n",
    "    batch = upsert_data[i:i + batch_size]\n",
    "    index.upsert(\n",
    "        vectors=batch,\n",
    "        namespace=\"bi-internal-ideas\"\n",
    "    )\n",
    "\n",
    "print(\"Data successfully upserted to Pinecone!\")\n",
    "\n",
    "# Step 6: Query the Pinecone index\n",
    "def query_pinecone(query_text, index, top_k=5):\n",
    "    \"\"\"Query Pinecone index with a text input.\"\"\"\n",
    "    query_embedding = embeddings.embed_query(query_text)\n",
    "    response = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        namespace=\"bi-internal-ideas\"\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# Example query\n",
    "query_text = input(\"Enter a query to search the index: \")\n",
    "results = query_pinecone(query_text, index)\n",
    "print(f\"Query Results: {results}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
